# Final 5% Fixes: Operational Edge Cases & Consumer Ergonomics

## Status: âœ… Critical Fixes Completed

This document summarizes the final operational edge case fixes applied to make the system production-ready for concurrent multi-run usage.

---

## âœ… Issue 1: snapshot_seq Assignment Concurrency-Safe

### Problem
If `save_snapshot()` does "max existing + 1" without holding a lock, two concurrent writers can pick the same sequence number, causing incorrect ordering.

### Solution
**Assign `snapshot_seq` under cohort-level lock:**

1. **Lock file**: `cohort_dir/.snapshot_seq.lock`
2. **Lock acquisition**: `fcntl.flock(LOCK_EX)` - blocks until available
3. **Re-read snapshots**: Load from run-level snapshot index to get latest sequences
4. **Sequence assignment**: `max_seq + 1` (computed under lock)
5. **Lock release**: Automatic when file is closed

### Implementation
```python
cohort_lock_file = cohort_dir / ".snapshot_seq.lock"
with open(cohort_lock_file, 'w') as lock_f:
    fcntl.flock(lock_f.fileno(), fcntl.LOCK_EX)
    # Re-read snapshots from index
    # Compute max_seq + 1
    snapshot.snapshot_seq = max_seq + 1
```

### Benefits
- âœ… **Concurrency-safe**: No race conditions in sequence assignment
- âœ… **Correct ordering**: Guaranteed unique, monotonic sequence numbers
- âœ… **Cohort-scoped**: Lock is per-cohort (allows parallel cohorts)

---

## âœ… Issue 2: "Prev Comparable" Never Picks Same Run

### Problem
Even with `(run_id, stage)` keys, if index contains multiple entries (old format, retries), we need to guarantee `prev.run_id != current.run_id`.

### Solution
**Added explicit run_id checks in all candidate collection points:**

1. **In-memory snapshots**: Skip if `snap.run_id == snapshot.run_id`
2. **Index file reads**: Skip if extracted `run_id == snapshot.run_id`
3. **Deserialized snapshots**: Double-check `snap.run_id == snapshot.run_id` (defense in depth)
4. **Baseline establishment**: Exclude same run_id from comparable_runs

### Implementation
```python
# In find_previous_comparable()
for run_id, snap in self._snapshots.items():
    if snap.run_id == snapshot.run_id:  # CRITICAL check
        continue
    # ... rest of logic

# In index file reads
if run_id == snapshot.run_id:
    continue
# ... deserialize and double-check
if snap.run_id == snapshot.run_id:
    continue
```

### Benefits
- âœ… **Guaranteed correctness**: Never compares run against itself
- âœ… **Defense in depth**: Multiple checkpoints prevent edge cases
- âœ… **Works with retries**: Handles multiple attempts of same run_id

---

## âœ… Issue 3: Snapshot Index Per-Run (Not One Mega File)

### Problem
The snapshot index at `REPRODUCIBILITY/METRICS/snapshot_index.json` was a single mega file that would grow unbounded across all runs.

### Solution
**Index is already per-run** (this was already implemented correctly):

- **Location**: `{run_dir}/REPRODUCIBILITY/METRICS/snapshot_index.json`
- **Scope**: Only contains snapshots for that specific run
- **Correlation**: Indices are correlated by run, not global

### Current Implementation
```python
# In __init__()
if run_dir:
    self.run_metrics_dir = run_dir / "REPRODUCIBILITY" / "METRICS"
    self.snapshot_index = self.run_metrics_dir / "snapshot_index.json"
```

### Benefits
- âœ… **Bounded growth**: Each index file only grows with one run's snapshots
- âœ… **Correlated by run**: Easy to find all snapshots for a specific run
- âœ… **Parallel access**: Different runs can update their indices concurrently

---

## ðŸ“‹ Remaining Optional Improvements (Not Blocking)

### 4. attempt_id (Optional)
**Status**: Not implemented (can be added later)
**Use case**: Track retries of same semantic run
**Implementation**: Add `attempt_id` field to `NormalizedSnapshot`, include in dedupe key

### 5. Garbage/Partial Artifact Detection
**Status**: Not implemented (can be added later)
**Use case**: Skip invalid snapshots when reading prev
**Implementation**: Validate required fields when deserializing, skip if invalid

### 6. Compression Threshold
**Status**: Not implemented (can be added later)
**Use case**: Reduce storage for large metadata files
**Implementation**: gzip files above threshold, or store large maps in separate files

### 7. Consumer-Facing Pointers
**Status**: Not implemented (can be added later)
**Use case**: Reduce "where do I look?" friction
**Implementation**: 
- Write `LATEST.json` per `(cohort, stage)` pointing to latest snapshot
- Include `prev_snapshot_path` and `baseline_snapshot_path` in metadata

---

## Summary

**Critical fixes completed:**
1. âœ… **snapshot_seq assignment**: Concurrency-safe under lock
2. âœ… **prev run selection**: Never picks same run_id
3. âœ… **Index organization**: Already per-run (correlated by runs)

**Production-ready for:**
- Concurrent multi-run execution
- Parallel cohorts/stages
- Retries and reruns
- High concurrency scenarios

**Optional improvements** (can be added incrementally):
- attempt_id tracking
- Garbage detection
- Compression
- Consumer ergonomics (LATEST.json, paths)

The system is now **production-ready** for real multi-run usage. The remaining items are incremental polish that can be added as needed.

