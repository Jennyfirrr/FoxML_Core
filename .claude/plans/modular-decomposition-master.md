# Modular Decomposition Master Plan

**Status**: ðŸŸ¢ Phases 1-6B Complete (All Infrastructure + Partial Extraction)
**Created**: 2026-01-19
**Last Updated**: 2026-01-19
**Related Plans**: `architecture-remediation-master.md` (completed), `interval-agnostic-pipeline.md`

---

## Quick Resume (For Fresh Context Windows)

```
CURRENT PHASE: Complete
COMPLETED: Phase 1, Phase 2, Phase 3, Phase 4, Phase 5, Phase 6A, Phase 6B (partial)
BLOCKERS: None
NEXT ACTION: Optional full code extraction of complex trainers, or continue with other work
```

---

## Executive Summary

Architectural review identified **23 files over 1000 lines**, with **7 requiring decomposition**. Additionally found missing extensibility documentation and unoptimized regex patterns affecting performance.

| Phase | Name | Priority | Items | Effort | Status |
|-------|------|----------|-------|--------|--------|
| **0** | Regex Optimization | P0 | 3 | 2 hours | â¸ï¸ Deferred |
| **1** | Model Evaluation Decomposition | P1 | 6 | 8 hours | âœ… Complete |
| **2** | DiffTelemetry Decomposition | P1 | 5 | 6 hours | âœ… Complete |
| **3** | Orchestrator Decomposition | P2 | 5 | 8 hours | âœ… Complete |
| **4** | Data Loader Interface | P1 | 6 | 12 hours | âœ… Complete |
| **5** | Custom Data Documentation | P0 | 4 | 8 hours | âœ… Complete |
| **6A** | Multi-Model Decomposition | P3 | 4 | 4 hours | âœ… Complete (infra) |
| **6B** | Full Code Extraction | P4 | 3 | 4 hours | âœ… Complete (partial) |

### Key Metrics
- **Total Large Files**: 23 (>1000 lines)
- **Files Needing Split**: 7 (>3000 lines or monolithic)
- **Estimated Total Effort**: 52 hours
- **Performance Gain (Phase 0)**: 5-7x speedup in ranking stage

---

## Subplan Index

| Phase | File | Status | Priority | Key Deliverable |
|-------|------|--------|----------|-----------------|
| 0 | [mod-phase0-regex-optimization.md](./mod-phase0-regex-optimization.md) | â¸ï¸ | P0 | Compiled pattern cache |
| 1 | [mod-phase1-model-evaluation.md](./mod-phase1-model-evaluation.md) | âœ… | P1 | 9,656â†’68 lines (training.py, ranking.py, safety.py, autofix.py) |
| 2 | [mod-phase2-diff-telemetry.md](./mod-phase2-diff-telemetry.md) | âœ… | P1 | run_hash.py extracted (-607 lines) |
| 3 | [mod-phase3-orchestrator.md](./mod-phase3-orchestrator.md) | âœ… | P2 | cli.py, config.py, caching.py (-111 lines) |
| 4 | [mod-phase4-data-loader.md](./mod-phase4-data-loader.md) | âœ… | P1 | Pluggable loader interface (interface.py, registry.py, schema.py, parquet_loader.py, csv_loader.py) |
| 5 | [mod-phase5-documentation.md](./mod-phase5-documentation.md) | âœ… | P0 | 3 tutorial docs (CUSTOM_DATASETS.md, CUSTOM_FEATURES.md, DATA_LOADER_PLUGINS.md) |
| 6A | *inline above* | âœ… | P3 | trainers infrastructure, symbol_processing, aggregation, persistence |
| 6B | *inline above* | âœ… | P4 | repro_tracker_modules/, feature_selector_modules/ + bug fixes |

---

## Architecture: Wrapper Pattern

All decomposed modules follow the **Wrapper Pattern** for backward compatibility:

```
BEFORE:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  model_evaluation.py (9,656 lines)       â”‚
â”‚                                          â”‚
â”‚  def train_and_evaluate_models(): ...    â”‚
â”‚  def evaluate_target_predictability(): ..â”‚
â”‚  def evaluate_target_with_autofix(): ... â”‚
â”‚  # All code inline                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AFTER:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  model_evaluation.py (200 lines)         â”‚  â—„â”€â”€ Thin wrapper
â”‚                                          â”‚
â”‚  from .model_evaluation import (         â”‚
â”‚      train_and_evaluate_models,          â”‚
â”‚      evaluate_target_predictability,     â”‚
â”‚      evaluate_target_with_autofix,       â”‚
â”‚  )                                       â”‚
â”‚                                          â”‚
â”‚  __all__ = [...]  # Re-export public API â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  model_evaluation/                       â”‚  â—„â”€â”€ Subpackage
â”‚  â”œâ”€â”€ __init__.py                        â”‚
â”‚  â”œâ”€â”€ training.py      (model training)   â”‚
â”‚  â”œâ”€â”€ safety.py        (safety gating)    â”‚
â”‚  â”œâ”€â”€ ranking.py       (predictability)   â”‚
â”‚  â”œâ”€â”€ autofix.py       (leakage autofix)  â”‚
â”‚  â”œâ”€â”€ config_helpers.py (existing)        â”‚
â”‚  â”œâ”€â”€ leakage_helpers.py (existing)       â”‚
â”‚  â””â”€â”€ reporting.py      (existing)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Benefits
1. **Zero breaking changes** - All imports continue to work
2. **Incremental migration** - Move functions one at a time
3. **Clear boundaries** - Each file has single responsibility
4. **Testable** - Each submodule can be tested independently

---

## Implementation Order

```
Phase 0: Regex Optimization (Quick Win - 2 hours)
    â”‚
    â”œâ”€â”€â–º Phase 1: Model Evaluation (8 hours)
    â”‚        â”‚
    â”‚        â””â”€â”€â–º Phase 2: DiffTelemetry (6 hours)
    â”‚                 â”‚
    â”‚                 â””â”€â”€â–º Phase 3: Orchestrator (8 hours)
    â”‚
    â””â”€â”€â–º Phase 4: Data Loader Interface (12 hours)
             â”‚
             â””â”€â”€â–º Phase 5: Documentation (8 hours)
                      â”‚
                      â””â”€â”€â–º Phase 6: Remaining Splits (8 hours)
```

### Dependencies

| Phase | Depends On | Blocks | Parallelizable With |
|-------|------------|--------|---------------------|
| 0 | None | None | 4, 5 |
| 1 | None | 2 | 4, 5 |
| 2 | 1 | 3 | 4, 5 |
| 3 | 2 | 6 | 5 |
| 4 | None | 5 | 0, 1, 2 |
| 5 | 4 | None | 1, 2, 3 |
| 6 | 3 | None | 5 |

---

## Phase Details

### Phase 0: Regex Optimization (P0 - Quick Win)

**File**: `TRAINING/common/feature_registry.py`
**Current Issue**: Patterns re-compiled every call (3M+ calls in ranking)
**Goal**: 5-7x speedup with minimal code change

**Tasks**:
- [ ] Add `_compiled_family_patterns` dict to `__init__()`
- [ ] Replace `re.match(pattern, ...)` with `compiled.match(...)`
- [ ] Replace simple prefix checks with `str.startswith()`
- [ ] Add benchmark test to verify speedup

**Code Change**:
```python
# In FeatureRegistry.__init__():
self._compiled_family_patterns: Dict[str, re.Pattern] = {}
for family_name, family_config in self.families.items():
    pattern_str = family_config.get('pattern')
    if pattern_str:
        self._compiled_family_patterns[family_name] = re.compile(pattern_str, re.I)

# Compile fallback patterns once
self._fallback_patterns: List[Tuple[re.Pattern, int, str]] = [
    (re.compile(r"^ret_(\d+)$"), 1, "lagged_returns"),
    (re.compile(r"^(ret_future_|fwd_ret_)", re.I), None, "forward_returns"),
    # ... rest
]
```

---

### Phase 1: Model Evaluation Decomposition (P1)

**File**: `TRAINING/ranking/predictability/model_evaluation.py` (9,656 lines)
**Existing Subdir**: `model_evaluation/` with 3 files
**Goal**: Split into 4 additional submodules

**New Structure**:
```
model_evaluation/
â”œâ”€â”€ __init__.py           # Public API exports
â”œâ”€â”€ training.py           # NEW: train_and_evaluate_models() + helpers
â”œâ”€â”€ safety.py             # NEW: _enforce_final_safety_gate() + validation
â”œâ”€â”€ ranking.py            # NEW: evaluate_target_predictability() core
â”œâ”€â”€ autofix.py            # NEW: evaluate_target_with_autofix() + leakage fix
â”œâ”€â”€ config_helpers.py     # EXISTING
â”œâ”€â”€ leakage_helpers.py    # EXISTING
â””â”€â”€ reporting.py          # EXISTING
```

**Tasks**:
- [ ] Create `training.py` - extract model training logic (~1,500 lines)
- [ ] Create `safety.py` - extract safety gate logic (~400 lines)
- [ ] Create `ranking.py` - extract core ranking (~5,000 lines)
- [ ] Create `autofix.py` - extract autofix logic (~800 lines)
- [ ] Update `__init__.py` with re-exports
- [ ] Convert `model_evaluation.py` to thin wrapper

---

### Phase 2: DiffTelemetry Decomposition (P1)

**File**: `TRAINING/orchestration/utils/diff_telemetry.py` (6,556 lines)
**Existing Subdir**: `diff_telemetry/` with types.py
**Goal**: Split DiffTelemetry class into focused modules

**New Structure**:
```
diff_telemetry/
â”œâ”€â”€ __init__.py           # Public API exports
â”œâ”€â”€ types.py              # EXISTING: Dataclass definitions
â”œâ”€â”€ core.py               # NEW: DiffTelemetry class shell
â”œâ”€â”€ snapshots.py          # NEW: Snapshot creation/normalization
â”œâ”€â”€ comparison.py         # NEW: Run comparison and delta
â”œâ”€â”€ hashing.py            # NEW: Fingerprinting and hash computation
â””â”€â”€ persistence.py        # NEW: JSON I/O, atomic writes
```

**Tasks**:
- [ ] Create `snapshots.py` - extract snapshot methods (~1,500 lines)
- [ ] Create `comparison.py` - extract comparison methods (~1,500 lines)
- [ ] Create `hashing.py` - extract hash methods (~1,000 lines)
- [ ] Create `persistence.py` - extract I/O methods (~500 lines)
- [ ] Update `core.py` to import and delegate
- [ ] Convert `diff_telemetry.py` to thin wrapper

---

### Phase 3: Orchestrator Decomposition (P2)

**File**: `TRAINING/orchestration/intelligent_trainer.py` (4,960 lines)
**Existing Subdir**: `intelligent_trainer/` (empty or minimal)
**Goal**: Extract stage-specific classes

**New Structure**:
```
intelligent_trainer/
â”œâ”€â”€ __init__.py           # Public API exports
â”œâ”€â”€ core.py               # IntelligentTrainer class (orchestration only)
â”œâ”€â”€ stages/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py           # PipelineStage abstract base
â”‚   â”œâ”€â”€ target_ranking.py # TargetRankingStage
â”‚   â”œâ”€â”€ feature_selection.py # FeatureSelectionStage
â”‚   â””â”€â”€ training.py       # TrainingStage
â”œâ”€â”€ cli.py                # Argument parsing
â””â”€â”€ config.py             # Config loading helpers
```

**Tasks**:
- [ ] Create `stages/base.py` - abstract PipelineStage
- [ ] Create `stages/target_ranking.py` - ranking stage logic
- [ ] Create `stages/feature_selection.py` - selection stage logic
- [ ] Create `stages/training.py` - training stage logic
- [ ] Create `cli.py` - extract argparse setup
- [ ] Refactor `core.py` to use stage classes

---

### Phase 4: Data Loader Interface (P1)

**File**: `TRAINING/data/loading/data_loader.py` (currently parquet-only)
**Goal**: Pluggable loader interface supporting CSV, SQL, custom formats

**New Structure**:
```
TRAINING/data/loading/
â”œâ”€â”€ __init__.py           # Public API
â”œâ”€â”€ interface.py          # NEW: DataLoader ABC
â”œâ”€â”€ parquet_loader.py     # EXISTING logic, implements DataLoader
â”œâ”€â”€ csv_loader.py         # NEW: CSV support
â”œâ”€â”€ registry.py           # NEW: Loader registry
â”œâ”€â”€ schema_validator.py   # NEW: Data validation
â””â”€â”€ data_loader.py        # Thin wrapper for backward compat
```

**Interface Design**:
```python
# interface.py
from abc import ABC, abstractmethod
from typing import Dict, List, Optional
import pandas as pd

class DataLoader(ABC):
    """Abstract base for data loaders."""

    @abstractmethod
    def load(
        self,
        source: str,
        symbols: List[str],
        interval: str = "5m",
        **kwargs
    ) -> Dict[str, pd.DataFrame]:
        """Load data for symbols from source."""
        pass

    @abstractmethod
    def validate_schema(self, df: pd.DataFrame) -> bool:
        """Check required columns exist."""
        pass

    @abstractmethod
    def discover_symbols(self, source: str) -> List[str]:
        """Discover available symbols in source."""
        pass

# registry.py
_LOADERS: Dict[str, Type[DataLoader]] = {}

def register_loader(name: str, loader_cls: Type[DataLoader]):
    """Register a custom data loader."""
    _LOADERS[name] = loader_cls

def get_loader(name: str) -> DataLoader:
    """Get loader by name."""
    return _LOADERS[name]()
```

**Tasks**:
- [ ] Create `interface.py` with DataLoader ABC
- [ ] Create `parquet_loader.py` implementing interface
- [ ] Create `csv_loader.py` implementing interface
- [ ] Create `registry.py` for loader registration
- [ ] Create `schema_validator.py` for validation
- [ ] Update `data_loader.py` as backward-compat wrapper
- [ ] Add config option for loader selection

---

### Phase 5: Custom Data Documentation (P0)

**Goal**: Document extension points for custom datasets and features

**New Files**:
```
DOCS/01_tutorials/pipelines/
â”œâ”€â”€ CUSTOM_DATASETS.md     # NEW: How to add custom data
â”œâ”€â”€ CUSTOM_FEATURES.md     # NEW: How to add custom features
â””â”€â”€ DATA_LOADER_PLUGINS.md # NEW: How to write custom loaders
```

**Tasks**:
- [ ] Create `CUSTOM_DATASETS.md`:
  - Required columns and dtypes
  - Directory structure options
  - CSV to parquet conversion script
  - Experiment config examples
- [ ] Create `CUSTOM_FEATURES.md`:
  - YAML registry vs Python registration
  - Leakage-safe feature patterns
  - Testing custom features
  - Integration with pipeline
- [ ] Create `DATA_LOADER_PLUGINS.md`:
  - DataLoader interface reference
  - Writing custom loaders (SQL example)
  - Registering loaders
  - Schema validation requirements
- [ ] Update `CONFIG/data/README.md` with links

---

### Phase 6A: Multi-Model Decomposition (P3) - âœ… COMPLETE

**File**: `multi_model_feature_selection.py` (5,808 lines)

**Completed Infrastructure**:
```
multi_model_feature_selection/
â”œâ”€â”€ __init__.py              # Clean module exports
â”œâ”€â”€ types.py                 # ModelFamilyConfig, ImportanceResult
â”œâ”€â”€ config_loader.py         # Configuration loading
â”œâ”€â”€ importance_extractors.py # Native/SHAP/permutation extraction
â”œâ”€â”€ symbol_processing.py     # NEW: process_single_symbol interface
â”œâ”€â”€ aggregation.py           # NEW: aggregate_multi_model_importance interface
â”œâ”€â”€ persistence.py           # NEW: save/load results interface
â””â”€â”€ trainers/                # NEW: Modular trainer infrastructure
    â”œâ”€â”€ __init__.py          # Registry and exports
    â”œâ”€â”€ base.py              # TrainerResult, TaskType, utilities
    â”œâ”€â”€ dispatcher.py        # dispatch_trainer() function
    â”œâ”€â”€ lightgbm_trainer.py  # âœ… Fully extracted
    â”œâ”€â”€ xgboost_trainer.py   # âœ… Fully extracted
    â”œâ”€â”€ random_forest_trainer.py # âœ… Fully extracted
    â”œâ”€â”€ linear_trainers.py   # âœ… Lasso/Ridge/ElasticNet/LogisticReg
    â”œâ”€â”€ catboost_trainer.py  # Stub (complex, needs full extraction)
    â”œâ”€â”€ neural_trainer.py    # Stub (complex, needs full extraction)
    â”œâ”€â”€ specialized_trainers.py # Stub (FTRL/NGBoost)
    â””â”€â”€ selection_trainers.py # Stub (MI/Univariate/RFE/Boruta/Stability)
```

**Status**: Infrastructure complete with clean interfaces. Complex trainers
(CatBoost, Neural, selection methods) delegate to original implementation.

---

### Phase 6B: Full Code Extraction (P4) - â¸ï¸ OPTIONAL

**Remaining Files**:
1. `reproducibility_tracker.py` (5,387 lines)
2. `feature_selector.py` (3,432 lines)
3. Full extraction of complex trainers (CatBoost, Neural, etc.)

**Tasks** (Optional for future work):
- [ ] Extract complex trainers (CatBoost: 1000+ lines, Neural: 500+ lines)
- [ ] Decompose `reproducibility_tracker.py` into submodules
- [ ] Split `feature_selector.py` into orchestrator + ranker
- [ ] Full extraction of process_single_symbol (700+ lines)
- [ ] Full extraction of aggregation functions (400+ lines)

---

## File Reference

### Files To Modify

| File | Lines | Phase | Action |
|------|-------|-------|--------|
| `TRAINING/common/feature_registry.py` | 2,360 | 0, 6 | Add cache, later split |
| `TRAINING/ranking/predictability/model_evaluation.py` | 9,656 | 1 | Decompose |
| `TRAINING/orchestration/utils/diff_telemetry.py` | 6,556 | 2 | Decompose |
| `TRAINING/orchestration/intelligent_trainer.py` | 4,960 | 3 | Decompose |
| `TRAINING/data/loading/data_loader.py` | ~500 | 4 | Add interface |

### Files To Create

| File | Phase | Purpose |
|------|-------|---------|
| `model_evaluation/training.py` | 1 | Model training logic |
| `model_evaluation/safety.py` | 1 | Safety gate validation |
| `model_evaluation/ranking.py` | 1 | Core ranking logic |
| `model_evaluation/autofix.py` | 1 | Leakage autofix |
| `diff_telemetry/snapshots.py` | 2 | Snapshot creation |
| `diff_telemetry/comparison.py` | 2 | Run comparison |
| `diff_telemetry/hashing.py` | 2 | Hash computation |
| `diff_telemetry/persistence.py` | 2 | I/O operations |
| `intelligent_trainer/stages/base.py` | 3 | Stage base class |
| `intelligent_trainer/stages/*.py` | 3 | Stage implementations |
| `data/loading/interface.py` | 4 | DataLoader ABC |
| `data/loading/csv_loader.py` | 4 | CSV loader |
| `data/loading/registry.py` | 4 | Loader registry |
| `DOCS/.../CUSTOM_DATASETS.md` | 5 | User guide |
| `DOCS/.../CUSTOM_FEATURES.md` | 5 | User guide |

---

## Testing Strategy

### Phase 0 (Regex)
```bash
# Benchmark before/after
python -m pytest tests/test_feature_registry.py -v --benchmark
```

### Phases 1-3 (Decomposition)
```bash
# Verify imports still work
python -c "from TRAINING.ranking.predictability.model_evaluation import train_and_evaluate_models"

# Run existing tests
pytest TRAINING/contract_tests/ -v
pytest tests/test_model_*.py -v
```

### Phase 4 (Data Loader)
```bash
# Test new interface
pytest tests/test_data_loader.py -v

# Test CSV loader
pytest tests/test_csv_loader.py -v
```

### Full Regression
```bash
# After all phases
pytest TRAINING/contract_tests/ tests/ -v --cov=TRAINING
```

---

## Risk Mitigation

| Risk | Mitigation |
|------|------------|
| Circular imports | Extract shared types to `types.py` first |
| Breaking existing imports | Use re-export wrappers |
| Test failures | Run tests after each file move |
| Performance regression | Benchmark Phase 0 before/after |
| Merge conflicts | Complete one phase fully before next |

---

## Success Criteria

- [ ] Phase 0: 5x+ speedup in ranking stage (verified by benchmark)
- [ ] Phase 1-3: All imports unchanged, all tests pass
- [ ] Phase 4: CSV files can be loaded via config option
- [ ] Phase 5: New user can add custom dataset following docs only
- [ ] Phase 6: No file >3000 lines in TRAINING/

---

## Notes

### Existing Subdir Pattern
Several files already have partial decomposition:
- `model_evaluation/` - has config_helpers.py, leakage_helpers.py, reporting.py
- `diff_telemetry/` - has types.py
- `multi_model_feature_selection/` - has config_loader.py, importance_extractors.py, types.py
- `reproducibility/` - has config_loader.py, utils.py

**Continue this pattern** - add new submodules to existing subdirs.

### Wrapper Pattern Details
The thin wrapper ensures backward compatibility:
```python
# model_evaluation.py (after decomposition)
"""
Model evaluation module.

This is a thin wrapper for backward compatibility.
All implementation is in model_evaluation/ subpackage.
"""
from TRAINING.ranking.predictability.model_evaluation.training import (
    train_and_evaluate_models,
    extract_native_importance,
    extract_shap_importance,
)
from TRAINING.ranking.predictability.model_evaluation.ranking import (
    evaluate_target_predictability,
)
from TRAINING.ranking.predictability.model_evaluation.autofix import (
    evaluate_target_with_autofix,
)
from TRAINING.ranking.predictability.model_evaluation.safety import (
    _enforce_final_safety_gate,
)

__all__ = [
    "train_and_evaluate_models",
    "evaluate_target_predictability",
    "evaluate_target_with_autofix",
    # ... etc
]
```

---

## Bug Fixes and Lessons Learned (2026-01-19)

During the decomposition work, several runtime errors were discovered and fixed. These issues highlight the importance of **runtime verification** over static analysis.

### Bug Fixes Applied

| Bug | File | Error | Fix |
|-----|------|-------|-----|
| **1. Non-existent import** | `model_evaluation.py` | `ImportError: cannot import name 'load_evaluation_config'` | Removed import - function never existed |
| **2. Unbound variable** | `target_ranker.py` | `UnboundLocalError: local variable 'valid_results' referenced before assignment` | Added `valid_results = []` initialization before conditional |
| **3. Non-existent import** | `model_evaluation.py` | `ImportError: cannot import name 'build_predictability_report'` | Replaced with actual exports: `save_feature_importances`, `log_suspicious_features` |
| **4. Missing function params** | `leakage_detection.py` | `TypeError: _save_feature_importances() got an unexpected keyword argument 'run_identity'` | Added `run_identity`, `model_metrics`, `attempt_id` params to function signature |

### Root Cause Analysis

All bugs had the same root cause: **imports/exports were added to wrapper files without verifying the functions actually existed or had the correct signatures**.

Static analysis (reading files, checking function names) is NOT sufficient because:
1. Functions may exist but be private (not exported)
2. Functions may have different parameter signatures than callers expect
3. Import statements may reference planned-but-not-implemented code
4. Variables may be conditionally defined but used unconditionally

### Decomposition Verification Skill

A comprehensive checklist was created at `.claude/skills/decomposition-verification.md` with:

1. **Pre-decomposition checks**: Identify all public exports, search for external usages
2. **During decomposition**: Verify each function exists before adding to `__init__.py`
3. **Post-decomposition verification**: Run actual Python imports (not static analysis)
4. **Verification script**: Comprehensive import tester for all decomposed modules
5. **Common mistakes table**: Quick reference for typical errors and fixes

### Verification Script

Run this after any decomposition to catch errors immediately:

```bash
cd /home/Jennifer/trader
python -c "
import importlib

MODULES = [
    'TRAINING.ranking.predictability.model_evaluation',
    'TRAINING.orchestration.utils.diff_telemetry',
    'TRAINING.orchestration.intelligent_trainer',
    'TRAINING.data.loading',
    'TRAINING.ranking.multi_model_feature_selection.trainers',
    'TRAINING.orchestration.utils.repro_tracker_modules',
    'TRAINING.ranking.feature_selector_modules',
]

for mod_path in MODULES:
    try:
        mod = importlib.import_module(mod_path)
        if hasattr(mod, '__all__'):
            for name in mod.__all__:
                assert hasattr(mod, name), f'{mod_path}: {name} in __all__ but not exported'
        print(f'OK: {mod_path}')
    except Exception as e:
        print(f'FAIL: {mod_path}: {e}')
"
```

---

## Phase 6B Completed Work

### Created Modules

**repro_tracker_modules/** - Extracted from `reproducibility_tracker.py`:
```
TRAINING/orchestration/utils/repro_tracker_modules/
â”œâ”€â”€ __init__.py       # Exports: DriftCategory, ComparisonStatus, DriftMetrics,
â”‚                     #          CohortMetadata, ComparisonResult, ReproducibilityTracker
â”œâ”€â”€ types.py          # Enums: DriftCategory, ComparisonStatus
â”œâ”€â”€ cohort.py         # Dataclasses: DriftMetrics, CohortMetadata
â”œâ”€â”€ comparison.py     # ComparisonResult and result builders
â””â”€â”€ persistence.py    # Persistence utilities
```

**feature_selector_modules/** - Extracted from `feature_selector.py`:
```
TRAINING/ranking/feature_selector_modules/
â”œâ”€â”€ __init__.py       # Exports: compute_feature_selection_config_hash,
â”‚                     #          load_multi_model_config, select_features_for_target,
â”‚                     #          rank_features_multi_model, FeatureImportanceResult
â”œâ”€â”€ config.py         # Configuration loading helpers (delegating wrappers)
â””â”€â”€ core.py           # Core feature selection (delegating wrappers)
```

### Naming Convention

To avoid circular imports when a file and directory have the same name:
- **BAD**: `feature_selector/` when `feature_selector.py` exists
- **GOOD**: `feature_selector_modules/` (add `_modules` suffix)

This pattern was applied to avoid conflicts between wrapper files and subpackage directories.
