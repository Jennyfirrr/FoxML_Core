# SPDX-License-Identifier: AGPL-3.0-or-later OR Commercial
# Copyright (c) 2025-2026 Fox ML Infrastructure LLC

"""
Overfitting Detection Utilities

Shared helper for determining when to skip expensive importance computation
due to overfitting. Used by both feature selection and model evaluation.
"""

from typing import Dict, Any, Optional, Tuple
import logging

logger = logging.getLogger(__name__)


def should_skip_expensive_importance(
    train_score: float,
    cv_score: Optional[float] = None,
    val_score: Optional[float] = None,
    n_features: Optional[int] = None,
    config: Optional[Dict[str, Any]] = None
) -> Tuple[bool, str, Dict[str, Any]]:
    """
    Determine if expensive importance computation should be skipped.
    
    Uses policy-based gating with multiple conditions:
    - Train accuracy threshold
    - Train/CV gap
    - Train/Val gap
    - Feature count cap (optional)
    
    Args:
        train_score: Training score (accuracy, RÂ², etc.)
        cv_score: Optional cross-validation mean score
        val_score: Optional validation score
        n_features: Optional number of features (for feature count cap)
        config: Optional config dict with thresholds (from safety_config.feature_importance)
    
    Returns:
        Tuple of (should_skip, reason, metadata):
        - should_skip: True if expensive importance should be skipped
        - reason: String reason for skipping (or "none" if not skipping)
        - metadata: Dict with train_score, cv_score, val_score, gaps, etc.
    """
    # Load thresholds from config
    if config is None:
        config = {}
    
    train_acc_threshold = config.get('overfit_train_acc_threshold', 0.99)
    gap_threshold = config.get('overfit_train_val_gap_threshold', 0.20)
    pvc_feature_count_cap = config.get('pvc_feature_count_cap', None)
    
    metadata = {
        'train_score': train_score,
        'cv_score': cv_score,
        'val_score': val_score,
        'n_features': n_features
    }
    
    # Check 1: Train accuracy threshold
    if train_score >= train_acc_threshold:
        metadata['train_acc_threshold'] = train_acc_threshold
        return True, f"train_acc_{train_score:.4f}_>=_{train_acc_threshold}", metadata
    
    # Check 2: Train/CV gap
    if cv_score is not None:
        gap = train_score - cv_score
        metadata['train_cv_gap'] = gap
        if gap >= gap_threshold:
            metadata['gap_threshold'] = gap_threshold
            return True, f"train_cv_gap_{gap:.4f}_>=_{gap_threshold}", metadata
    
    # Check 3: Train/Val gap
    if val_score is not None:
        gap = train_score - val_score
        metadata['train_val_gap'] = gap
        if gap >= gap_threshold:
            metadata['gap_threshold'] = gap_threshold
            return True, f"train_val_gap_{gap:.4f}_>=_{gap_threshold}", metadata
    
    # Check 4: Feature count cap (optional)
    if pvc_feature_count_cap is not None and n_features is not None:
        if n_features >= pvc_feature_count_cap:
            metadata['pvc_feature_count_cap'] = pvc_feature_count_cap
            return True, f"n_features_{n_features}_>=_{pvc_feature_count_cap}", metadata
    
    return False, "none", metadata

